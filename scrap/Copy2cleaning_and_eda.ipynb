{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425b9a3d-633b-4645-8cc8-096140332ca5",
   "metadata": {},
   "source": [
    "# Data Cleaning and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b6088-17e5-4982-91e8-e32ef257132b",
   "metadata": {},
   "source": [
    "## Process of cleaning \n",
    "\n",
    "*Code written for cleaning in [cleaning.py](projects/project-3/code/cleaning.py).*\n",
    "\n",
    "* We'll pass a list of the csv files from reddit into a function that cleans and concatenates the csvs into one dataframe.\n",
    "    * For our purposes, it doesn't make much sense to keep posts that are null in the \"selftext\" column.\n",
    "    * Next, I will remove any rows where this is the case. We'll also rename the \"Unnamed: 0\" column to \"post_id\".\n",
    "    * Also, let's remove the \"comments\", utc, and title columns. Pulled these in just in case, but for now, I am not planning to access them.\n",
    "    * I'll add a column that assign 0/1 values for the subreddit: 0 for the rpg subreddit, 1 for the osr subreddit\n",
    "    * Return the concatenated dataframe\n",
    "* Once the completed dataframe is created, use \"post_id\" to deduplicate the data. We'll get a final count of the subreddit post totals to see if we need to pull in more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7b91f44-8731-473b-b611-4514d05e239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"./\"))\n",
    "import importlib\n",
    "#importlib.reload(cleaning)  # Force reload the module\n",
    "\n",
    "\n",
    "import cleaning\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f1dad66-b908-4860-93f6-d410cb63ffa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/osr_244-489.csv',\n",
       " '../data/nsr_1000-1150.csv',\n",
       " '../data/osr_1931-2163.csv',\n",
       " '../data/osr_1683-1931.csv',\n",
       " '../data/nsr_1150-1394.csv',\n",
       " '../data/osr_0-243.csv',\n",
       " '../data/osr_490-1190.csv',\n",
       " '../data/osr_1190-1433.csv',\n",
       " '../data/nsr_1394-1628.csv',\n",
       " '../data/nsr_0-999.csv',\n",
       " '../data/nsr_1628-1862.csv',\n",
       " '../data/osr_1433-1683.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f\"../data/{file}\" for file in os.listdir(\"../data\") if file.endswith(\".csv\")]\n",
    "files.remove('../data/cleaned_df.csv')\n",
    "files.remove('../data/cleaned_with_sentiment_df.csv')\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cffc0e4-3af7-4beb-958b-fe589908951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = cleaning.clean_data(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "678a1b6f-a04c-43ab-b73e-ec981a0a03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = cleaned.drop_duplicates(subset=\"post_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1af8a29e-d872-46aa-a8f8-df646e9a1194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_osr\n",
       "1    1145\n",
       "0    1102\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned[\"is_osr\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54fc5a-6e09-436c-984b-a3adce49396c",
   "metadata": {},
   "source": [
    "### Now that we have at least 1000 posts from each of our subreddits, so I'm going to save our cleaned dataframe for safe keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfb35e23-8cfe-4835-854b-b5e5928467ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned.to_csv(\"../data/cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b67559-12c9-4a45-9c24-4235dd0ebe29",
   "metadata": {},
   "source": [
    "Want to do a sentiment analysis on posts from this subreddit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27627b52-14f9-42c9-884f-16c1a76533cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c270ebe-6e8e-4f14-be2f-e1da3b634dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2247, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_dict.html\n",
    "\n",
    "sentiment_data = [sa.polarity_scores(text) for text in cleaned[\"selftext\"]]\n",
    "sentiment_df = pd.DataFrame.from_dict(sentiment_data)\n",
    "sentiment_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fbdb198-4fd0-43f2-8608-98764d61d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.shape\n",
    "cleaned.head()\n",
    "cleaned.tail()\n",
    "\n",
    "# indexes are not unique, so I will reset them to make concatenation possible\n",
    "\n",
    "cleaned = cleaned.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad82c64b-c975-46ed-8acb-b9a4fb35fbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post_id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_osr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>243</td>\n",
       "      <td>1j0hj6f</td>\n",
       "      <td>Pretty much the title. I am curious in terms o...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>244</td>\n",
       "      <td>1j0gblw</td>\n",
       "      <td>I have a database of creature stats for PF2 an...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>246</td>\n",
       "      <td>1j0fy0e</td>\n",
       "      <td>Not an OSR player but running a hex crawl for ...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>247</td>\n",
       "      <td>1j0e1wc</td>\n",
       "      <td>I'm running an old school Adventure I won't na...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>248</td>\n",
       "      <td>1j0dwly</td>\n",
       "      <td>My wife has expressed interest in giving ttrpg...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  post_id                                           selftext  \\\n",
       "2242    243  1j0hj6f  Pretty much the title. I am curious in terms o...   \n",
       "2243    244  1j0gblw  I have a database of creature stats for PF2 an...   \n",
       "2244    246  1j0fy0e  Not an OSR player but running a hex crawl for ...   \n",
       "2245    247  1j0e1wc  I'm running an old school Adventure I won't na...   \n",
       "2246    248  1j0dwly  My wife has expressed interest in giving ttrpg...   \n",
       "\n",
       "     subreddit is_osr  \n",
       "2242       osr      1  \n",
       "2243       osr      1  \n",
       "2244       osr      1  \n",
       "2245       osr      1  \n",
       "2246       osr      1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63cd14f5-d02d-4da2-b0b7-f78e3df1c00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post_id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_osr</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1irnln3</td>\n",
       "      <td>HeroQuest is the perfect entry into OSR DND.  ...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.5313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1f3scds</td>\n",
       "      <td>To be clear, it was a lot of work before the g...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.9769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1di0qn6</td>\n",
       "      <td>So, I know there was a thread discussing peopl...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.3694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1g5ga0h</td>\n",
       "      <td>Really loving the booklet layout. Open up char...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1grfhij</td>\n",
       "      <td>In this video I discuss why I consider Castles...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  post_id                                           selftext  \\\n",
       "0      1  1irnln3  HeroQuest is the perfect entry into OSR DND.  ...   \n",
       "1      2  1f3scds  To be clear, it was a lot of work before the g...   \n",
       "2      3  1di0qn6  So, I know there was a thread discussing peopl...   \n",
       "3      4  1g5ga0h  Really loving the booklet layout. Open up char...   \n",
       "4      5  1grfhij  In this video I discuss why I consider Castles...   \n",
       "\n",
       "  subreddit is_osr    neg    neu    pos  compound  \n",
       "0       osr      1  0.118  0.708  0.174    0.5313  \n",
       "1       osr      1  0.094  0.760  0.147    0.9769  \n",
       "2       osr      1  0.066  0.859  0.075    0.3694  \n",
       "3       osr      1  0.000  0.758  0.242    0.9237  \n",
       "4       osr      1  0.000  0.701  0.299    0.5719  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = pd.concat([cleaned, sentiment_df],axis=1)\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2125d598-6e81-4bb6-a305-6fdbc54ff83d",
   "metadata": {},
   "source": [
    "Now that we have a dataframe with our reddit data, let's do some exploration on it. I will do some preprocessing on the dataframe here as well to be able to learn more about our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ceaa3527-9594-4cfc-8ce5-ecaa5047851e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_osr\n",
       "1    0.509568\n",
       "0    0.490432\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.shape\n",
    "cleaned[\"is_osr\"].value_counts(normalize=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5759777b-5608-4c72-8b46-fb63a076020a",
   "metadata": {},
   "source": [
    "Our baseline accuracy is 50.9% that subreddit will be from the osr subreddit.  First, let's normalize our text by our tokenizing, lemmatizing, stemming, and  removing special characters and stop words. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2bea337-06df-4bde-8c31-c72e6448cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "#lowercase all text in \"selftext\" column\n",
    "cleaned[\"selftext\"] = cleaned[\"selftext\"].map(lambda x: x.translate(translator).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "998b6d18-99e3-438b-8585-45cbed4879d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize text in \"selftext\" column\n",
    "cleaned[\"selftext\"] = [word_tokenize(post) for post in cleaned[\"selftext\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e1f7670-2081-424f-ae3f-aff99908354b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post_id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_osr</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1irnln3</td>\n",
       "      <td>[heroquest, is, the, perfect, entry, into, osr...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.5313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1f3scds</td>\n",
       "      <td>[to, be, clear, it, was, a, lot, of, work, bef...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.9769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1di0qn6</td>\n",
       "      <td>[so, i, know, there, was, a, thread, discussin...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.3694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1g5ga0h</td>\n",
       "      <td>[really, loving, the, booklet, layout, open, u...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1grfhij</td>\n",
       "      <td>[in, this, video, i, discuss, why, i, consider...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  post_id                                           selftext  \\\n",
       "0      1  1irnln3  [heroquest, is, the, perfect, entry, into, osr...   \n",
       "1      2  1f3scds  [to, be, clear, it, was, a, lot, of, work, bef...   \n",
       "2      3  1di0qn6  [so, i, know, there, was, a, thread, discussin...   \n",
       "3      4  1g5ga0h  [really, loving, the, booklet, layout, open, u...   \n",
       "4      5  1grfhij  [in, this, video, i, discuss, why, i, consider...   \n",
       "\n",
       "  subreddit is_osr    neg    neu    pos  compound  \n",
       "0       osr      1  0.118  0.708  0.174    0.5313  \n",
       "1       osr      1  0.094  0.760  0.147    0.9769  \n",
       "2       osr      1  0.066  0.859  0.075    0.3694  \n",
       "3       osr      1  0.000  0.758  0.242    0.9237  \n",
       "4       osr      1  0.000  0.701  0.299    0.5719  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76b26668-9108-42d7-96b7-b0750c9e9df3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post_id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_osr</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>num_of_token_wo_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1irnln3</td>\n",
       "      <td>[heroquest, perfect, entry, osr, dnd, sevenyea...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.5313</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1f3scds</td>\n",
       "      <td>[clear, lot, work, game, started, run, jacob, ...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1di0qn6</td>\n",
       "      <td>[know, thread, discussing, peoples, disappoint...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.3694</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1g5ga0h</td>\n",
       "      <td>[really, loving, booklet, layout, open, charac...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1grfhij</td>\n",
       "      <td>[video, discuss, consider, castles, crusades, ...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  post_id                                           selftext  \\\n",
       "0      1  1irnln3  [heroquest, perfect, entry, osr, dnd, sevenyea...   \n",
       "1      2  1f3scds  [clear, lot, work, game, started, run, jacob, ...   \n",
       "2      3  1di0qn6  [know, thread, discussing, peoples, disappoint...   \n",
       "3      4  1g5ga0h  [really, loving, booklet, layout, open, charac...   \n",
       "4      5  1grfhij  [video, discuss, consider, castles, crusades, ...   \n",
       "\n",
       "  subreddit is_osr    neg    neu    pos  compound  num_of_token_wo_stop  \n",
       "0       osr      1  0.118  0.708  0.174    0.5313                    20  \n",
       "1       osr      1  0.094  0.760  0.147    0.9769                   214  \n",
       "2       osr      1  0.066  0.859  0.075    0.3694                    82  \n",
       "3       osr      1  0.000  0.758  0.242    0.9237                    35  \n",
       "4       osr      1  0.000  0.701  0.299    0.5719                     8  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stop words\n",
    "cleaned[\"selftext\"] = cleaned[\"selftext\"].map(lambda x: [token for token in x if token not in stopwords.words(\"english\")])\n",
    "#column counting number of words after stop words removed\n",
    "cleaned[\"num_of_token_wo_stop\"] = cleaned[\"selftext\"].map(lambda x: len(x))\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233c5c5-4387-4f6d-98db-d2ec42edb47a",
   "metadata": {},
   "source": [
    "### Also decided know that number of tokens remaining after removing stop words would be interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4b9b83-612b-421a-8e4f-d5c1e774e1a1",
   "metadata": {},
   "source": [
    "#### people on these subreddits can be verbose, so we'll use stemming instead of lemmatizing. This will be faster and not require us to tag all of the text we currently have with the part of speech it belings to to ensure appropriate conjugation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75f381d7-af95-431d-9f16-fa835df93ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post_id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>is_osr</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>num_of_token_wo_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1irnln3</td>\n",
       "      <td>[heroquest, perfect, entri, osr, dnd, sevenyea...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.5313</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1f3scds</td>\n",
       "      <td>[clear, lot, work, game, start, run, jacob, fl...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1di0qn6</td>\n",
       "      <td>[know, thread, discuss, peopl, disappoint, sys...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.3694</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1g5ga0h</td>\n",
       "      <td>[realli, love, booklet, layout, open, charact,...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.9237</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1grfhij</td>\n",
       "      <td>[video, discuss, consid, castl, crusad, true, ...</td>\n",
       "      <td>osr</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  post_id                                           selftext  \\\n",
       "0      1  1irnln3  [heroquest, perfect, entri, osr, dnd, sevenyea...   \n",
       "1      2  1f3scds  [clear, lot, work, game, start, run, jacob, fl...   \n",
       "2      3  1di0qn6  [know, thread, discuss, peopl, disappoint, sys...   \n",
       "3      4  1g5ga0h  [realli, love, booklet, layout, open, charact,...   \n",
       "4      5  1grfhij  [video, discuss, consid, castl, crusad, true, ...   \n",
       "\n",
       "  subreddit is_osr    neg    neu    pos  compound  num_of_token_wo_stop  \n",
       "0       osr      1  0.118  0.708  0.174    0.5313                    20  \n",
       "1       osr      1  0.094  0.760  0.147    0.9769                   214  \n",
       "2       osr      1  0.066  0.859  0.075    0.3694                    82  \n",
       "3       osr      1  0.000  0.758  0.242    0.9237                    35  \n",
       "4       osr      1  0.000  0.701  0.299    0.5719                     8  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "cleaned[\"selftext\"] = cleaned[\"selftext\"].map(lambda x: [ps.stem(token) for token in x ])\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece1d35-3325-457b-bee8-063d5514f508",
   "metadata": {},
   "source": [
    "### **Let's save this dataframe for safe keeping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb464db7-380e-448d-89c9-f03a0697a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.to_csv(\"../data/cleaned_with_sentiment_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f373efd9-f19c-4814-89ea-ca9b2b16bb70",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# week 5: nlp1 nlp2\n",
    "\n",
    "# week 6: boosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b61b4a-aa60-41f6-9805-2964293ae88b",
   "metadata": {},
   "source": [
    "### Let's look at Countvectorizer\n",
    "#### We preprocessed the data by hand above, but CountVectorizer can do this for us as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a405793-fe37-41fe-a177-97d139ac9a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eda using CountVectorizing in nlp 2 lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fcc6b-cc27-47f1-925d-018985173cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58144d35-cb01-4084-b201-0a7a9fb1327d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6929ee8-49fe-4329-9a1f-59392f157fc1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe4387a8-b3c5-4625-89d4-98e2dc5346de",
   "metadata": {},
   "source": [
    "Since our classes are balanced, for now, we won't need to normalize our data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
